import os
import subprocess

# paths
ROOT = os.getcwd()
resources = os.path.join(ROOT, 'resources')

# variables
project_file = open('project.txt')
dataset = project_file.readline().strip()
project_file.close()

dataset_FC = 'Project_' + dataset + '_corrected_FC.tsv'
dataset_BF = 'Project_' + dataset + '_BF.tsv'
dataset_BF_scaled = 'Project_' + dataset + '_scaled_BF.tsv'

ESSENTIAL_GENE_SETS = ['ADaM', 'CEGv2']

n_cells = int(subprocess.getoutput('head -1 resources/FC/' + dataset_FC + ' | wc -w'))
SAMPLES = ['cell_line_' + str(idx) + '.tsv' for idx in range(1, n_cells-1)]

rule all:
    input:
        expand(os.path.join(resources, 'BF', '{essential_gene_sets}', dataset_BF_scaled),
                essential_gene_sets=ESSENTIAL_GENE_SETS),
        expand(os.path.join(resources, 'BF', '{essential_gene_sets}', 'Project_' + dataset + '_cells', '{samples}'),
                essential_gene_sets=ESSENTIAL_GENE_SETS, samples=SAMPLES)

rule splitter:
    input:
        os.path.join(resources, 'FC', dataset_FC)
    output:
        temp(expand(os.path.join(resources, 'FC', 'Project_' + dataset + '_cells', '{samples}'), 
                samples=SAMPLES))
    params:
        path = os.path.join(resources, 'FC', 'Project_' + dataset + '_cells')
    shell:
        """
        python3 workflows/data_preprocessing/src/cell_splitter.py -i {input} -o {params.path}
        """

rule run_BAGEL:
    input:
        cell_line = os.path.join(resources, 'FC', 'Project_' + dataset + '_cells', '{samples}'),
        essential = os.path.join('data', '{essential_gene_sets}.txt'),
        nonessential ='data/NEGv1.txt'
    output:
        os.path.join(resources, 'BF', '{essential_gene_sets}', 'Project_' + dataset + '_cells', '{samples}')
    params:
        seed = 1234,
        controls = 1
    shell:
        """
        python3 workflows/data_preprocessing/src/BAGEL.py bf -i {input.cell_line} -o {output} \
            -e {input.essential} -n {input.nonessential} -c {params.controls} -s {params.seed} -r -NS
        """

rule assembler:
    input:
        os.path.join(resources, 'BF', '{essential_gene_sets}', 'Project_' + dataset + '_cells', 'cell_line_1.tsv')
    output:
        temp(os.path.join(resources, 'BF', '{essential_gene_sets}', dataset_BF))
    params:
        path = os.path.join(resources, 'BF', '{essential_gene_sets}', 'Project_' + dataset + '_cells')
    shell:
        """
        python3 workflows/data_preprocessing/src/cell_assembler.py -i {params.path} -o {output}
        """

rule scaling:
    input:
        dataset = os.path.join(resources, 'BF', '{essential_gene_sets}', dataset_BF),
        essential = os.path.join('data', '{essential_gene_sets}.txt'),
        nonessential = 'data/NEGv1.txt'
    output:
        os.path.join(resources, 'BF', '{essential_gene_sets}', dataset_BF_scaled)
    params:
        fdr = 0.05
    shell:
        """
        python3 workflows/data_preprocessing/src/scaling.py -i {input.dataset} -e {input.essential} \
                -n {input.nonessential} -o {output} --fdr {params.fdr}
        """